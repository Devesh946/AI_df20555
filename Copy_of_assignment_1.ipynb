{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNZvrn2pst6Eehhlz+/d8X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devesh946/AI_df20555/blob/main/Copy_of_assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeQgIuLrIbIu"
      },
      "source": [
        "import pandas as pd\r\n",
        "import urllib.request\r\n",
        "import requests\r\n",
        "url=\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_text.txt\"\r\n",
        "\r\n",
        "r=requests.get(url,allow_redirects=True)\r\n",
        "data=open('train_text.txt','wb').write(r.content)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-fel1wIMVwM",
        "outputId": "514d2729-d18f-4988-c3cb-54589da4bca6"
      },
      "source": [
        "stream= open(\"train_text.txt\")\r\n",
        "tweets=stream.readlines()\r\n",
        "stream.close()\r\n",
        "print(tweets[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OH: “I had a blue penis while I was this” [playing with Google Earth VR] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "DIRPiHDU6RXw",
        "outputId": "2a59ca1a-401c-484b-b0da-519bb19c19cf"
      },
      "source": [
        "# code Credit https://github.com/cardiffnlp/tweeteval/blob/main/evaluation_script.py this is the github repository from which i have fetched the code.In no way i am claiming it as my own\r\n",
        "# usage: evaluaton_script.py [-h] [--tweeteval_path TWEETEVAL_PATH]\r\n",
        "#                            [--predictions_path PREDICTIONS_PATH] [--task TASK]\r\n",
        "\r\n",
        "# optional arguments:\r\n",
        "#   -h, --help: show this help message and exit\r\n",
        "#   --tweeteval_path: Path to TweetEval dataset\r\n",
        "#   --predictions_path: Path to predictions files\r\n",
        "#   --task: Use this to get single task detailed results\r\n",
        "#           (emoji|emotion|hate|irony|offensive|sentiment|stance)\r\n",
        "#\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "\r\n",
        "TASKS = [\r\n",
        "    'emoji', \r\n",
        "    'hate',\r\n",
        "    'offensive',]\r\n",
        "\r\n",
        "STANCE_TASKS = [\r\n",
        "    'abortion',\r\n",
        "    'atheism',\r\n",
        "    'climate',\r\n",
        "    'feminist',\r\n",
        "    'hillary']\r\n",
        "\r\n",
        "def load_gold_pred(args):\r\n",
        "    tweeteval_path = args.tweeteval_path\r\n",
        "    predictions_path = args.predictions_path\r\n",
        "    task = args.task\r\n",
        "\r\n",
        "    if 'stance' in task:\r\n",
        "        gold = []\r\n",
        "        pred = []\r\n",
        "        for stance_t in STANCE_TASKS:\r\n",
        "            gold_path = os.path.join(tweeteval_path,task,stance_t,'test_labels.txt')\r\n",
        "            pred_path = os.path.join(predictions_path,task,stance_t+'.txt')\r\n",
        "            gold.append(open(gold_path).read().split(\"\\n\")[:-1])\r\n",
        "            pred.append(open(pred_path).read().split(\"\\n\")[:-1])\r\n",
        "        # flatten lists of lists\r\n",
        "        gold = [p for each_target in gold for p in each_target]\r\n",
        "        pred = [p for each_target in pred for p in each_target]\r\n",
        "    else:\r\n",
        "        gold_path = os.path.join(tweeteval_path,task,'test_labels.txt')\r\n",
        "        pred_path = os.path.join(predictions_path,task+'.txt')\r\n",
        "        gold = open(gold_path).read().split(\"\\n\")[:-1]\r\n",
        "        pred = open(pred_path).read().split(\"\\n\")[:-1]\r\n",
        "        \r\n",
        "    return gold, pred\r\n",
        "\r\n",
        "def single_task_results(args):\r\n",
        "    task = args.task\r\n",
        "    tweeteval_result = -1\r\n",
        "    results = {}\r\n",
        "    \r\n",
        "    try:\r\n",
        "        gold, pred = load_gold_pred(args)\r\n",
        "        results = classification_report(gold, pred, output_dict=True)\r\n",
        "\r\n",
        "        # Emoji (Macro f1)\r\n",
        "        if 'emoji' in task:\r\n",
        "            tweeteval_result = results['macro avg']['f1-score'] \r\n",
        "\r\n",
        "        # Emotion (Macro f1)\r\n",
        "        elif 'emotion' in task:\r\n",
        "            tweeteval_result = results['macro avg']['f1-score'] \r\n",
        "\r\n",
        "        # Hate (Macro f1)\r\n",
        "        elif 'hate' in task:\r\n",
        "            tweeteval_result = results['macro avg']['f1-score'] \r\n",
        "\r\n",
        "        # Irony (Irony class f1)\r\n",
        "        elif 'irony' in task:\r\n",
        "            tweeteval_result = results['1']['f1-score'] \r\n",
        "\r\n",
        "        # Offensive (Macro f1)\r\n",
        "        elif 'offensive' in task:\r\n",
        "            tweeteval_result = results['macro avg']['f1-score'] \r\n",
        "\r\n",
        "        # Sentiment (Macro Recall)\r\n",
        "        elif 'sentiment' in task:\r\n",
        "            tweeteval_result = results['macro avg']['recall']\r\n",
        "\r\n",
        "        # Stance (Macro F1 of 'favor' and 'against' classes)\r\n",
        "        elif 'stance' in task:\r\n",
        "            f1_against = results['1']['f1-score']\r\n",
        "            f1_favor = results['2']['f1-score']\r\n",
        "            tweeteval_result = (f1_against+f1_favor) / 2\r\n",
        "            \r\n",
        "    except Exception as ex:\r\n",
        "        print(f\"Issues with task {task}: {ex}\")\r\n",
        "        \r\n",
        "    return tweeteval_result, results\r\n",
        "\r\n",
        "def is_all_good(all_tweeteval_results):\r\n",
        "    return all([r != -1 for r in all_tweeteval_results.values()])\r\n",
        "\r\n",
        "\r\n",
        "if __name__==\"__main__\":\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser(description='TweetEval evaluation script.')\r\n",
        "    \r\n",
        "    parser.add_argument('--tweeteval_path', default=\"./datasets/\", type=str, help='Path to TweetEval datasets')\r\n",
        "    parser.add_argument('--predictions_path', default=\"./predictions/\", type=str, help='Path to predictions files')\r\n",
        "    parser.add_argument('--task', default=\"\", type=str, help='Indicate this parameter to get single task detailed results')\r\n",
        "\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    if args.task == \"\":\r\n",
        "        all_tweeteval_results = {}\r\n",
        "        \r\n",
        "        # Results for each task\r\n",
        "        for t in TASKS:\r\n",
        "            args.task = t\r\n",
        "            all_tweeteval_results[t], _ = single_task_results(args)\r\n",
        "            \r\n",
        "        # Print results (score=-1 if some results are missing)\r\n",
        "        print(f\"{'-'*30}\")\r\n",
        "        if is_all_good(all_tweeteval_results):\r\n",
        "            tweeteval_final_score = sum(all_tweeteval_results.values())/len(all_tweeteval_results.values())\r\n",
        "        else:\r\n",
        "            tweeteval_final_score = -1\r\n",
        "        for t in TASKS:\r\n",
        "            # Each score\r\n",
        "            print(f\"{t}: {all_tweeteval_results[t]}\") \r\n",
        "        # Final score\r\n",
        "        print(f\"{'-'*30}\\nTweetEval Score: {tweeteval_final_score}\")\r\n",
        "        \r\n",
        "    else:\r\n",
        "        # Detailed results of one single task (--task parameter)\r\n",
        "        tweeteval_resut, results = single_task_results(args)\r\n",
        "        for k in results:\r\n",
        "            print(k, results[k])\r\n",
        "        print(f\"{'-'*30}\\nTweetEval Score ({args.task}): {tweeteval_resut}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--tweeteval_path TWEETEVAL_PATH]\n",
            "                             [--predictions_path PREDICTIONS_PATH]\n",
            "                             [--task TASK]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-1bfa8c39-521d-4953-a3b1-d7b27ce05e08.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}